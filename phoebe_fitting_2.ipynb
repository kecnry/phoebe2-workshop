{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial we will use the basic functionallity of EMCEE (the MCMC software) to fit a synthetic binary that we make using phoebe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline \n",
    "import numpy as np\n",
    "import emcee\n",
    "import matplotlib.pyplot as pl\n",
    "import phoebe\n",
    "import matplotlib.mlab as mlab\n",
    "from matplotlib.pyplot import cm "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we make our synthetic data, this time we will make a binary star using PHOEBE and add noise:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logger = phoebe.logger(clevel='WARNING')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "b = phoebe.default_binary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we will add a light curve data set so that we cam make our synthetic data model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "times = np.linspace(0,1,51)\n",
    "b.add_dataset('lc', times=times, dataset='lc01')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will set the irradiation method to \"none\" (for the purpose of the tutorial) as that requires significant computational time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "b.get_parameter(context='compute', qualifier='irrad_method').set_value(\"none\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will also significantly reduce the number of triangles to speed up computations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "b.get_parameter(context='compute', component='primary', qualifier='ntriangles').set_value(300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "b.get_parameter(context='compute', component='secondary', qualifier='ntriangles').set_value(300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will set the parameters that we plan to fit to specific values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b['incl@binary@orbit@component'] = 86.5\n",
    "b['rpole@primary@star@component'] = 1.2\n",
    "b['rpole@secondary@star@component'] = 0.8\n",
    "b['q@binary@orbit@component'] = 0.7\n",
    "b['pblum@primary@dataset'] = 2.9*np.pi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will compute our phoebe model, add noise and plot the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b.run_compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "flux = b['fluxes@latest@model'].get_value()\n",
    "sigma = 0.01\n",
    "mean = 0.0\n",
    "noise = np.random.normal(mean, sigma, flux.shape)\n",
    "noisy = flux + noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.plot(times, noisy, \"b.-\")\n",
    "pl.xlabel(\"Times\")\n",
    "pl.ylabel(\"Flux\")\n",
    "pl.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have our data, we need to set the hyperparamters required to run emcee. Here the prior boxes provide the lower and upper limits for the phoebe parameter values. We will select the order to be incl, rpole1, rpole2, mass ratio, luminosity:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nwalkers = 12\n",
    "niter = 10\n",
    "prior_boxes = [(85.,87.),(1.1,1.3),(0.7,0.9),(0.65,0.75),(2.8*np.pi,3.0*np.pi)]\n",
    "sigma = 0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will set up a new bundle, which we will call \"mod\", to compute the model to fit the synthetic data we just generated:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mod = phoebe.default_binary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will need to generate the model at the same times as our data (or make it at equidistant points and interpolate). Also, if you have a large observed data set and your phased light curve does not change in time (due to effects such as apsidal motion or a third body), I recommend only computing one orbital cycle of the model and extrapolating to the whole data set before computing the merit function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "times = np.linspace(0,1,51)\n",
    "mod.add_dataset('lc', times=times, dataset='lc01')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, for the purpose of speeding up computations we will set the number of triangles to a (ridiciously) low value and turn off reflection:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mod.get_parameter(context='compute', qualifier='irrad_method').set_value(\"none\")\n",
    "mod.get_parameter(context='compute', component='primary', qualifier='ntriangles').set_value(300)\n",
    "mod.get_parameter(context='compute', component='secondary', qualifier='ntriangles').set_value(300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate an initial guess for all the parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rpars(prior_boxes):\n",
    "    return [np.random.rand() * (p[1]-p[0]) + p[0] for p in prior_boxes]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here the priors are flat (meaning they are just linearly distributed between two numbers). If we wish to specify Gaussian priors, we could set our prior boxes to specify the mean and sigma values, and use the following function to determine our priors:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "return [random.gauss(p[0],p[1]) for p in pars]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will specify our log probability function, which will include our figure of merit computation. Here, z will be the array of values returned by the mcmc algorithm. We will update the parameter values with the new values given by the mcmc fitter in this function and then recompute the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lnprob(z):\n",
    "\n",
    "    mod['incl@binary@orbit@component'] = z[0]\n",
    "    mod['rpole@primary@star@component'] = z[1]\n",
    "    mod['rpole@secondary@star@component'] = z[2]\n",
    "    mod['q@binary@orbit@component'] = z[3]\n",
    "    mod['pblum@primary@dataset'] = z[4]\n",
    "    \n",
    "    mod.run_compute()\n",
    "        \n",
    "    model = mod['fluxes@latest@model'].get_value()\n",
    "\n",
    "    # use chi^2 to compare the model to the data:\n",
    "    chi2 = 0.\n",
    "    for i in range (len(times)):\n",
    "            chi2+=((noisy[i]-model[i])**2)/(sigma**2)\n",
    "\n",
    "    # calculate lnp\n",
    "    lnp = -0.5*chi2\n",
    "\n",
    "    return lnp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will set the run function which will combine all our computations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run(prior_boxes, nwalkers, niter):\n",
    "    # Specify the number of dimensions for mcmc\n",
    "    ndim = len(prior_boxes)\n",
    "\n",
    "    # Generate initial guesses for all parameters for all chains\n",
    "    p0 = np.array([rpars(prior_boxes) for i in xrange(nwalkers)])\n",
    "\n",
    "    # Generate the emcee sampler. Here the inputs provided include the lnprob function. With this setup, the value z\n",
    "    # in the lnprob function, is the output from the sampler.\n",
    "    sampler = emcee.EnsembleSampler(nwalkers,ndim,lnprob)\n",
    "    \n",
    "    pos, prob, state = sampler.run_mcmc(p0, niter)\n",
    "    \n",
    "    for i in range(ndim):\n",
    "        pl.figure()\n",
    "        y = sampler.flatchain[:,i]\n",
    "        n, bins, patches = pl.hist(y, 200, normed=1, color=\"b\", alpha=0.45)#, histtype=\"step\")\n",
    "        pl.title(\"Dimension {0:d}\".format(i))\n",
    "        \n",
    "        mu = np.average(y)\n",
    "        sigma = np.std(y)\n",
    "        \n",
    "        print \"mu = \", mu\n",
    "        print \"sigma = \",sigma\n",
    "\n",
    "        bf = mlab.normpdf(bins, mu, sigma)\n",
    "        l = pl.plot(bins, bf, 'k--', linewidth=2.0)\n",
    "    pl.show()\n",
    "    return pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos = run(prior_boxes, nwalkers, niter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "If we wish to see how good our last fit was, we can overplot the final models and the synthetic data. To do this, we will need to update the model with the last parameter values from our fit, and then overplot each one:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color=cm.rainbow(np.linspace(0,1,nwalkers))\n",
    "for i,c in zip(range(nwalkers),color):\n",
    "  \n",
    "    #pl.figure()\n",
    "    \n",
    "    # Set all the parameter values\n",
    "    mod['incl@binary@orbit@component'] = pos[-1-i,0]\n",
    "    mod['rpole@primary@star@component'] = pos[-1-i,1]\n",
    "    mod['rpole@secondary@star@component'] = pos[-1-i,2]\n",
    "    mod['q@binary@orbit@component'] = pos[-1-i,3]\n",
    "    mod['pblum@primary@dataset'] = pos[-1-i,4]\n",
    "        \n",
    "    mod.run_compute()\n",
    "    \n",
    "    model = mod['fluxes@latest@model'].get_value()\n",
    "    \n",
    "    pl.plot(times,model,c=c)\n",
    "\n",
    "pl.xlabel(\"Times\")\n",
    "pl.ylabel(\"Flux\")\n",
    "pl.plot(times,noisy,\"k.\")\n",
    "pl.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see there is still a large spread of models. The key here is that we need to do lots of iterations. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
